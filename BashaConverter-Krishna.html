<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>BhashaConvert · Advanced AI Translation</title>
  <!-- Tailwind CSS -->
  <script src="https://cdn.tailwindcss.com"></script>
  <script>
    tailwind.config = {
      theme: {
        extend: {
          fontFamily: { sans: ["Inter", "ui-sans-serif", "system-ui"] },
          colors: { neon: { 500: '#6ef3ff' }, accent: { 600: '#8b5cf6' } }
        }
      }
    };
  </script>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600;700&display=swap" rel="stylesheet">
  <!-- External libs (free, client-side) -->
  <script src="https://unpkg.com/mammoth/mammoth.browser.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pdf.js/2.13.216/pdf.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jszip/3.10.1/jszip.min.js"></script>
  <script src="https://unpkg.com/tesseract.js@v4.0.2/dist/tesseract.min.js"></script>
  <!-- PDF generation library -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jspdf/2.5.1/jspdf.umd.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.4.1/html2canvas.min.js"></script>
  <!-- Audio processing -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/wavesurfer.js/7.7.3/wavesurfer.min.js"></script>
  <style>
    .nav-active { border-bottom: 3px solid #8b5cf6; color: #8b5cf6; }
    .nav-btn { border-bottom: 3px solid transparent; transition: color .2s, border-color .2s; }
    .panel { display: none; }
    .panel.active { display: block; }
    .glass {
      background: rgba(255,255,255,.09);
      box-shadow: 0 2px 12px rgba(0,0,0,.08);
      backdrop-filter: blur(10px);
    }
    .card {
      background: rgba(255,255,255,.05);
      border: 1px solid rgba(255,255,255,.1);
      border-radius: 1rem;
      padding: 1.5rem;
      margin-bottom: 2rem;
    }
    .rounded-xl { border-radius: 1rem; }
    .input, .btn, .btn-primary {
      border-radius: 6px;
      border: none;
      transition: all 0.2s ease;
    }
    .input { 
      padding: 12px; 
      background: rgba(15, 24, 58, 0.8); 
      color: #fff; 
      width: 100%; 
      border: 1px solid rgba(255,255,255,0.1);
    }
    .input:focus {
      outline: none;
      border-color: #8b5cf6;
      box-shadow: 0 0 0 3px rgba(139, 92, 246, 0.1);
    }
    .btn { 
      background: rgba(36, 43, 73, 0.8); 
      color: #fff; 
      padding: 10px 20px; 
      cursor: pointer;
      border: 1px solid rgba(255,255,255,0.1);
    }
    .btn-primary { 
      background: linear-gradient(135deg, #8b5cf6, #6ef3ff); 
      color: #fff; 
      padding: 10px 20px; 
      cursor: pointer;
      font-weight: 600;
    }
    .btn:hover { 
      background: rgba(68, 75, 105, 0.9); 
      transform: translateY(-1px);
    }
    .btn-primary:hover { 
      background: linear-gradient(135deg, #6ef3ff, #8b5cf6); 
      color: #071029; 
      transform: translateY(-1px);
    }
    
    /* Video panel specific styles */
    .video-container {
      background: rgba(0,0,0,0.3);
      border-radius: 1rem;
      padding: 1rem;
      margin: 1rem 0;
    }
    
    .subtitle-segment {
      background: rgba(139, 92, 246, 0.1);
      border: 1px solid rgba(139, 92, 246, 0.3);
      border-radius: 0.5rem;
      padding: 0.75rem;
      margin: 0.5rem 0;
    }
    
    .subtitle-segment[contenteditable="true"]:focus {
      outline: none;
      border-color: #6ef3ff;
      background: rgba(110, 243, 255, 0.1);
    }
    
    /* File upload styling */
    input[type="file"] {
      background: rgba(15, 24, 58, 0.8);
      border: 1px solid rgba(255,255,255,0.1);
      border-radius: 0.5rem;
      padding: 0.5rem;
      color: white;
      width: 100%;
    }
    
    /* Loading states */
    .loading {
      opacity: 0.6;
      pointer-events: none;
    }
    
    /* Success/Error message styling */
    .message {
      padding: 0.75rem;
      border-radius: 0.5rem;
      margin: 0.5rem 0;
      font-size: 0.875rem;
    }
    
    .message.success {
      background: rgba(34, 197, 94, 0.1);
      border: 1px solid rgba(34, 197, 94, 0.3);
      color: #22c55e;
    }
    
    .message.warning {
      background: rgba(245, 158, 11, 0.1);
      border: 1px solid rgba(245, 158, 11, 0.3);
      color: #f59e0b;
    }
    
    .message.error {
      background: rgba(239, 68, 68, 0.1);
      border: 1px solid rgba(239, 68, 68, 0.3);
      color: #ef4444;
    }
    
    /* Audio visualization */
    .audio-visualizer {
      background: rgba(0,0,0,0.2);
      border-radius: 0.5rem;
      padding: 1rem;
      margin: 1rem 0;
    }
    
    /* Chat interface */
    .chat-interface {
      position: fixed;
      top: 50%;
      right: 20px;
      transform: translateY(-50%);
      width: 350px;
      max-height: 80vh;
      background: rgba(15, 24, 58, 0.95);
      border: 1px solid rgba(139, 92, 246, 0.3);
      border-radius: 1rem;
      backdrop-filter: blur(20px);
      z-index: 1000;
      display: none;
    }
    
    .chat-interface.active {
      display: block;
    }
    
    .chat-header {
      background: linear-gradient(135deg, #8b5cf6, #6ef3ff);
      padding: 1rem;
      border-radius: 1rem 1rem 0 0;
      display: flex;
      justify-content: space-between;
      align-items: center;
    }
    
    .chat-toggle {
      position: fixed;
      top: 20px;
      right: 20px;
      background: linear-gradient(135deg, #8b5cf6, #6ef3ff);
      border: none;
      color: white;
      padding: 0.75rem;
      border-radius: 50%;
      cursor: pointer;
      z-index: 1001;
      box-shadow: 0 4px 15px rgba(139, 92, 246, 0.3);
    }
    
    /* Responsive improvements */
    @media (max-width: 768px) {
      .card {
        padding: 1rem;
      }
      .grid {
        grid-template-columns: 1fr !important;
      }
      .chat-interface {
        width: 90vw;
        right: 5vw;
      }
    }
  </style>
</head>
<body class="min-h-screen bg-[#071029] text-white font-sans p-0">
  <!-- Chat Toggle Button -->
  <button class="chat-toggle" onclick="toggleChat()" title="Real-time Chat Translator">
    💬
  </button>

  <!-- Chat Interface -->
  <div id="chatInterface" class="chat-interface">
    <div class="chat-header">
      <h3 class="font-semibold">💬 Real-time Chat Translator</h3>
      <button onclick="toggleChat()" class="text-white hover:text-gray-200">✕</button>
    </div>
    <div class="p-4">
      <div class="mb-3">
        <select id="chatFromLang" class="input text-sm">
          <option value="auto">Auto Detect</option>
          <option value="en">English</option>
          <option value="hi">Hindi</option>
          <option value="mr">Marathi</option>
          <option value="gu">Gujarati</option>
          <option value="ta">Tamil</option>
          <option value="bn">Bengali</option>
          <option value="te">Telugu</option>
          <option value="kn">Kannada</option>
        </select>
        <select id="chatToLang" class="input text-sm mt-2">
          <option value="hi">Hindi</option>
          <option value="mr">Marathi</option>
          <option value="gu">Gujarati</option>
          <option value="ta">Tamil</option>
          <option value="bn">Bengali</option>
          <option value="en">English</option>
          <option value="te">Telugu</option>
          <option value="kn">Kannada</option>
        </select>
      </div>
      <textarea id="chatInput" class="input text-sm min-h-[80px]" placeholder="Type your message..."></textarea>
      <button class="btn-primary w-full mt-2 text-sm" onclick="translateChat()">Translate & Send</button>
      <div id="chatHistory" class="mt-3 max-h-[300px] overflow-y-auto text-sm">
        <div class="text-white/60 text-xs">Chat messages will appear here...</div>
      </div>
      <div class="flex gap-2 mt-3">
        <button class="btn text-xs" onclick="clearChat()">Clear</button>
        <button class="btn text-xs" onclick="downloadChat()">Download</button>
      </div>
    </div>
  </div>

  <div class="max-w-6xl mx-auto px-4 pt-8 pb-6">
    <header class="mb-8 flex items-center justify-between">
      <h1 class="text-3xl font-bold tracking-tight">Bhasha-Converter <span class="text-accent-600">Krishna</span></h1>
      <div class="text-sm text-white/70">🚀 Advanced AI Translation • 8 Languages • Real-time Processing • Free Forever</div>
    </header>
    
    <!-- Competitive Features Banner -->
    <div class="mb-6 p-4 bg-gradient-to-r from-accent-600/20 to-neon-500/20 rounded-xl border border-accent-600/30">
      <div class="flex items-center justify-between">
        <div class="flex items-center space-x-4">
          <div class="flex items-center space-x-2">
            <span class="text-green-400">✓</span>
            <span class="text-sm">No API Keys Required</span>
          </div>
          <div class="flex items-center space-x-2">
            <span class="text-green-400">✓</span>
            <span class="text-sm">100% Free</span>
          </div>
          <div class="flex items-center space-x-2">
            <span class="text-green-400">✓</span>
            <span class="text-sm">Privacy First</span>
          </div>
        </div>
        <div class="text-right">
          <div class="text-xs text-white/60">Unique Features</div>
          <div class="text-sm font-semibold">PDF Generation • OCR • Audio Analysis</div>
        </div>
      </div>
    </div>

    <!-- Navigation Bar -->
    <nav class="mb-8 border-b border-white/15 flex space-x-4">
      <button class="nav-btn text-lg py-2 px-4 nav-active" data-panel="text-panel">Text</button>
      <button class="nav-btn text-lg py-2 px-4" data-panel="audio-panel">Audio</button>
      <button class="nav-btn text-lg py-2 px-4" data-panel="document-panel">Document</button>
      <button class="nav-btn text-lg py-2 px-4" data-panel="video-panel">Video</button>
    </nav>

    <!-- Panels -->
    <div id="text-panel" class="panel active">
      <!-- Text translation panel -->
      <section class="card">
        <h2 class="text-xl font-semibold mb-3">🚀 Advanced Text Translation Engine</h2>
        <div class="grid lg:grid-cols-2 gap-6">
          <div>
            <label class="text-sm text-white/70">Source Language</label>
            <select id="fromLang" class="input mt-1">
              <option value="auto">Auto Detect</option>
              <option value="en">English</option>
              <option value="hi">Hindi</option>
              <option value="mr">Marathi</option>
              <option value="gu">Gujarati</option>
              <option value="ta">Tamil</option>
              <option value="bn">Bengali</option>
              <option value="te">Telugu</option>
              <option value="kn">Kannada</option>
            </select>
            <label class="text-sm text-white/70 mt-4">Domain (context)</label>
            <select id="domain" class="input mt-1">
              <option>General</option>
              <option>Legal</option>
              <option>Medical</option>
              <option>Education</option>
              <option>eCommerce</option>
              <option>Technical</option>
              <option>Creative</option>
            </select>
            <label class="text-sm text-white/70 mt-4">Input Text</label>
            <textarea id="inputText" class="input mt-1 min-h-[120px]" placeholder="Type or paste text here..."></textarea>
            <div class="flex gap-2 mt-4 flex-wrap">
              <button class="btn-primary" onclick="translateText()">Translate ▶</button>
              <button class="btn" onclick="grammarFix()">Grammar Fix</button>
              <button class="btn" onclick="rewriteStyle('formal')">Rewrite (Formal)</button>
              <button class="btn" onclick="rewriteStyle('informal')">Rewrite (Informal)</button>
            </div>
            <div class="mt-4 flex gap-3 items-center flex-wrap">
              <button class="btn" id="micBtn" onclick="startListening()">🎙 Start Mic</button>
              <button class="btn" onclick="stopListening()">⏹ Stop Mic</button>
              <button class="btn" onclick="clearInput()">Clear</button>
            </div>
            <div class="mt-3 text-xs text-white/60">
              ✨ Advanced AI translation with context awareness • Grammar correction • Style adaptation
            </div>
          </div>
          <div>
            <label class="text-sm text-white/70">Target Language</label>
            <select id="toLang" class="input mt-1">
              <option value="hi">Hindi</option>
              <option value="mr">Marathi</option>
              <option value="gu">Gujarati</option>
              <option value="ta">Tamil</option>
              <option value="bn">Bengali</option>
              <option value="en">English</option>
              <option value="te">Telugu</option>
              <option value="kn">Kannada</option>
            </select>
            <label class="text-sm text-white/70 mt-4">Tone</label>
            <div class="flex gap-2 mt-1">
              <button class="btn" onclick="setTone('neutral')">Neutral</button>
              <button class="btn" onclick="setTone('formal')">Formal</button>
              <button class="btn" onclick="setTone('informal')">Informal</button>
            </div>
            <label class="text-sm text-white/70 mt-4">Output</label>
            <textarea id="outputText" class="input mt-1 min-h-[120px]" readonly></textarea>
            <div class="flex gap-2 mt-4">
              <button class="btn" onclick="copyOut()">Copy</button>
              <button class="btn" onclick="speakText()">🔊 Speak</button>
              <button class="btn" onclick="downloadTxt('translation.txt', document.getElementById('outputText').value)">Download</button>
            </div>
          </div>
        </div>
      </section>
    </div>

    <div id="audio-panel" class="panel">
      <!-- Voice & Audio -->
      <section class="card">
        <h2 class="text-xl font-semibold mb-3">🎵 Advanced Voice & Audio Translation</h2>
        <div class="grid lg:grid-cols-2 gap-6">
          <div>
            <label class="text-sm text-white/70">Live Speech → Translate</label>
            <div class="mt-2 glass rounded-xl p-3">
              <div id="liveTranscript" class="text-sm text-white/80 min-h-[80px]">Transcript will appear here when you use the mic.</div>
              <div class="mt-3 flex gap-2">
                <button class="btn-primary" onclick="startTranslateLive()">Start Live Translate</button>
                <button class="btn" onclick="stopTranslateLive()">Stop</button>
              </div>
            </div>
            <div class="mt-4">
              <label class="text-sm text-white/70">Upload Audio (MP3 / WAV)</label>
              <input type="file" id="audioFile" accept="audio/*" class="mt-2" onchange="handleAudioUpload(event)" />
              <div class="mt-3 flex gap-2">
                <button class="btn-primary" onclick="transcribeAudio()">Transcribe Audio</button>
                <button class="btn" onclick="translateAudio()">Translate Audio</button>
              </div>
              <div class="text-xs text-white/60 mt-2">
                🎯 Advanced audio processing with waveform visualization and speaker detection
              </div>
            </div>
          </div>
          <div>
            <label class="text-sm text-white/70">Audio Visualization & Processing</label>
            <div id="audioVisualizer" class="audio-visualizer">
              <div class="text-white/60 text-sm">Audio waveform will appear here after upload</div>
            </div>
            <label class="text-sm text-white/70 mt-4">Speaker diarization / Timestamps</label>
            <div class="glass rounded-xl p-3 min-h-[120px]">
              <div id="diarizeList" class="text-sm text-white/80">(Speaker segments and timestamps will be listed here after transcription)</div>
            </div>
          </div>
        </div>
      </section>
    </div>

    <div id="document-panel" class="panel">
      <!-- Document Translation -->
      <section class="card">
        <h2 class="text-xl font-semibold mb-3">📄 Advanced Document Translation</h2>
        <div class="grid lg:grid-cols-2 gap-6">
          <div>
            <label class="text-sm text-white/70">Upload Document (PDF / DOCX / PPTX)</label>
            <input type="file" id="docFile" accept=".pdf,.docx,.pptx" class="mt-2" onchange="handleDocUpload(event)" />
            <div class="mt-3 text-xs text-white/60">✨ Advanced parsing with format preservation • PDF generation • Layout maintenance</div>
            <div class="mt-3 flex gap-2">
              <button class="btn-primary" onclick="translateDocument()">Translate Document</button>
              <button class="btn" onclick="downloadTranslatedPDF()">Download PDF</button>
              <button class="btn" onclick="downloadTxt('document_translation.txt', document.getElementById('docTranslated').innerText)">Download TXT</button>
            </div>
          </div>
          <div>
            <label class="text-sm text-white/70">Side_by_Side Preview</label>
            <div class="grid grid-cols-2 gap-2 mt-2">
              <div id="docOriginal" class="glass rounded-xl p-3 min-h-[140px] overflow-auto text-sm">Original preview</div>
              <div id="docTranslated" class="glass rounded-xl p-3 min-h-[140px] overflow-auto text-sm">Translated preview</div>
            </div>
          </div>
        </div>
      </section>
    </div>

    <div id="video-panel" class="panel">
      <!-- Video Translation -->
      <section class="card">
        <h2 class="text-xl font-semibold mb-3">🎬 Advanced Video Content Translation</h2>
        <div class="grid lg:grid-cols-2 gap-6">
          <div>
            <label class="text-sm text-white/70">Upload video or paste link (YouTube/Vimeo)</label>
            <input type="file" id="videoFile" accept="video/*" class="mt-2" onchange="handleVideoUpload(event)" />
            <input id="videoLink" class="input mt-2" placeholder="Paste YouTube/Vimeo link (optional)" />
            <button class="btn mt-2" onclick="loadVideoFromLink()">Load from Link</button>
            <div class="mt-3 flex gap-2">
              <button class="btn-primary" onclick="startVideoTranscription()">Transcribe (play & capture)</button>
              <button class="btn" onclick="stopVideoTranscription()">Stop Transcription</button>
              <button class="btn" onclick="extractOCR()">OCR Frame</button>
            </div>
            <div class="text-xs text-white/60 mt-2">
              🎯 Advanced video processing with multi-language subtitle support and OCR integration
            </div>
          </div>
          <div>
            <label class="text-sm text-white/70">Preview & Subtitle Generator</label>
            <div class="video-container">
              <video id="previewVideo" controls class="w-full rounded-xl bg-black">Your browser does not support HTML5 video.</video>
            </div>
            <div class="mt-3">
              <label class="text-sm text-white/70">Subtitle Language</label>
              <select id="subtitleLang" class="input mt-1">
                <option value="en">English</option>
                <option value="hi">Hindi</option>
                <option value="mr">Marathi</option>
                <option value="gu">Gujarati</option>
                <option value="ta">Tamil</option>
                <option value="bn">Bengali</option>
                <option value="te">Telugu</option>
                <option value="kn">Kannada</option>
              </select>
            </div>
            <div class="mt-3 flex gap-2">
              <button class="btn" onclick="downloadSRT()">Download SRT</button>
              <button class="btn" onclick="downloadVTT()">Download VTT</button>
            </div>
            <div id="subtitleEditor" class="mt-3 text-sm text-white/80">Subtitle editor will appear here after transcription.</div>
          </div>
        </div>
      </section>
      
      <section class="card">
        <h2 class="text-xl font-semibold mb-3">🎯 Video Subtitles Generator</h2>
        <div class="text-sm text-white/80">
          ✨ Advanced subtitle generation with language options, OCR text extraction, and timestamp synchronization. 
          Export in multiple formats for professional use.
        </div>
      </section>
    </div>

    <footer id="contact" class="card">
      <div class="container">
        <h2 class="section-title text-xl font-semibold mb-3">Contact</h2>
        <div class="flex gap-3 flex-wrap">
          <span class="chip bg-accent-600 px-3 py-2 rounded-full text-sm">✉️ 202krishnapatil@gmail.com</span>
          <span class="chip bg-accent-600 px-3 py-2 rounded-full text-sm">📞 +91 95801 59631</span>
          <a class="chip bg-accent-600 px-3 py-2 rounded-full text-sm hover:bg-accent-500 transition-colors" target="_blank" rel="noopener" href="https://in.linkedin.com/in/krishna-chandrakant-patil-33969536b">in LinkedIn</a>
        </div>
        <p class="muted text-white/60 mt-4">© <span id="y"></span> Krishna Patil • Advanced AI Translation System</p>
      </div>
    </footer>
  </div>

<script>
  // Nav tab switching
  document.querySelectorAll('.nav-btn').forEach(btn => {
    btn.addEventListener('click', function() {
      document.querySelectorAll('.nav-btn').forEach(b => b.classList.remove('nav-active'));
      this.classList.add('nav-active');
      document.querySelectorAll('.panel').forEach(p => p.classList.remove('active'));
      const panelId = this.getAttribute('data-panel');
      const panel = document.getElementById(panelId);
      if (panel) panel.classList.add('active');
    });
  });

// --- Helpers & language locale map ---
const LANG_TO_LOCALE = {
  en: 'en-US', hi: 'hi-IN', mr: 'mr-IN', gu: 'gu-IN', ta: 'ta-IN',
  bn: 'bn-IN', te: 'te-IN', kn: 'kn-IN', es: 'es-ES', fr: 'fr-FR',
  de: 'de-DE', ja: 'ja-JP'
};

function langToLocale(code){
  if(!code) return 'en-US';
  if(LANG_TO_LOCALE[code]) return LANG_TO_LOCALE[code];
  // if user passed e.g. "en-US" already, return it
  if(code.includes('-')) return code;
  return code + '-IN'; // fallback (for many Indian langs)
}

function $id(id){ return document.getElementById(id); }

function parseGoogleTranslate(data){
  // translate_a/single returns nested arrays: data[0] => segments: [[translated, original, ...], ...]
  try{
    if(Array.isArray(data) && Array.isArray(data[0])){
      return data[0].map(seg => (Array.isArray(seg) ? (seg[0]||'') : '')).join('');
    }
    // fallback: maybe responseData style
    if(data && data.responseData && data.responseData.translatedText) return data.responseData.translatedText;
    return '';
  }catch(e){
    console.warn('parseGoogleTranslate error', e);
    return '';
  }
}

function escapeRegex(s){ return s.replace(/[.*+?^${}()|[\]\\]/g,'\\$&'); }

function applyReplacements(text, replacements){
  if(!replacements || typeof replacements !== 'object') return text;
  let out = text;
  const keys = Object.keys(replacements).sort((a,b)=> b.length - a.length);
  for(const k of keys){
    if(!k) continue;
    const v = replacements[k];
    const isLatin = /[A-Za-z]/.test(k);
    if(isLatin){
      const re = new RegExp('\\b' + escapeRegex(k) + '\\b', 'ig');
      out = out.replace(re, (m) => {
        // preserve capitalization
        if(m[0] === m[0].toUpperCase()) return v.charAt(0).toUpperCase() + v.slice(1);
        return v;
      });
    } else {
      const re = new RegExp(escapeRegex(k), 'g');
      out = out.replace(re, v);
    }
  }
  return out;
}

// small rule maps for rewriteStyle (expand these for your demo)
const RULES = {
  en: {
    formal: {
      "hi":"hello", "hey":"hello", "thanks":"thank you", "gonna":"going to", "wanna":"want to", "ok":"okay"
    },
    informal: {
      "hello":"hey", "please inform me":"let me know", "please":"pls", "do not":"don't"
    }
  },
  hi: {
    formal: { "हाय":"नमस्कार", "हेलो":"नमस्कार", "बताओ":"कृपया बताइए" },
    informal: { "नमस्कार":"हाय", "कृपया":"प्लीज" }
  },
  default: { formal: {}, informal: {} }
};

// simple grammar heuristics per language
function grammarFixSimple(text, lang){
  if(!text) return text;
  lang = (lang||'en').toLowerCase();
  // English: punctuation/spacing, sentence capitalization
  if(lang === 'en'){
    let t = text.replace(/\s+/g,' ').trim();
    t = t.replace(/\s+([,?.!;:])/g,'$1'); // fix spaces before punctuation
    t = t.replace(/([.!?])\s*([a-z])/g, (m,p,c)=> p + ' ' + c.toUpperCase()); // capitalize after sentence end
    t = t.replace(/^([a-z])/,(m,c)=> c.toUpperCase()); // capitalize first char
    t = t.replace(/(\s)+/g,' ');
    return t;
  }
  // Devanagari / Indian languages: normalize spaces & punctuation
  if(['hi','mr','gu','bn','te','kn','ta'].includes(lang)){
    let t = text.replace(/\s+/g,' ').trim();
    t = t.replace(/\s+([,।!?])/g,'$1');
    return t;
  }
  // fallback generic normalization
  return text.replace(/\s+/g,' ').trim();
}

/* -------------------- Translation function -------------------- */
/* Returns the translated string (and sets outputText). Uses google translate public endpoint */
async function translateText(){
  const input = $id('inputText').value.trim();
  const fromLang = $id('fromLang').value || 'auto';
  const toLang = $id('toLang').value || 'en';
  if(!input){ alert('Please enter some text.'); return ''; }

  const domain = $id('domain') ? $id('domain').value : 'General';
  const contextual = (domain && domain !== 'General') ? `[Context:${domain}] ${input}` : input;

  const url = `https://translate.googleapis.com/translate_a/single?client=gtx&sl=${encodeURIComponent(fromLang)}&tl=${encodeURIComponent(toLang)}&dt=t&q=${encodeURIComponent(contextual)}`;

  try{
    const res = await fetch(url);
    if(!res.ok) throw new Error('HTTP '+res.status);
    const data = await res.json();
    const translated = parseGoogleTranslate(data) || '';
    $id('outputText').value = translated;
    return translated;
  }catch(err){
    console.error('Translate error', err);
    alert('Translation failed: ' + (err.message || err));
    return '';
  }
}

/* -------------------- Grammar Fix -------------------- */
/* This now: 1) gets the translated text (in target language) and 2) runs grammar heuristics */
async function grammarFix(){
  // get a translated base (ensures we're fixing the selected output language)
  const translated = await translateText();
  if(!translated) return;
  const toLang = $id('toLang').value || 'en';
  const fixed = grammarFixSimple(translated, toLang);
  $id('outputText').value = fixed;
}

/* -------------------- Rewrite (formal/informal) -------------------- */
async function rewriteStyle(style){
  // style: 'formal' or 'informal'
  const translated = await translateText();
  if(!translated) return;
  const toLang = $id('toLang').value || 'en';
  const rules = RULES[toLang] || RULES.default;
  let out = translated;
  if(style === 'formal' && rules.formal) out = applyReplacements(out, rules.formal);
  else if(style === 'informal' && rules.informal) out = applyReplacements(out, rules.informal);
  // apply a grammar normalization afterwards
  out = grammarFixSimple(out, toLang);
  $id('outputText').value = out;
}

/* -------------------- Enhanced Speech Recognition / Live Translate -------------------- */
let recognition = null;

function startListening(){
  // Enhanced browser compatibility check
  const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
  
  if(!SpeechRecognition){ 
    // Provide alternative solutions for unsupported browsers
    const alternatives = [
      'Speech Recognition is not supported in this browser.',
      'Please try:',
      '• Chrome/Edge (recommended)',
      '• Firefox with speech recognition extension',
      '• Use text input instead',
      '• Check microphone permissions'
    ].join('\n');
    
    alert(alternatives);
    return; 
  }
  
  if(recognition){ recognition.stop(); recognition = null; }
  
  try {
    recognition = new SpeechRecognition();
    const from = $id('fromLang').value || 'en';
    recognition.lang = langToLocale(from);
    recognition.interimResults = true;
    recognition.continuous = true;

    recognition.onresult = (event) => {
      let transcript = '';
      for(let i = event.resultIndex; i < event.results.length; ++i){
        transcript += event.results[i][0].transcript;
      }
      // show interim transcripts in input box (non-final)
      $id('inputText').value = transcript;
      
      // Update UI to show recognition is active
      const micBtn = document.getElementById('micBtn');
      if (micBtn) {
        micBtn.innerHTML = '🎙️ Listening...';
        micBtn.classList.add('btn-primary');
        micBtn.classList.remove('btn');
      }
    };
    
    recognition.onerror = (e) => {
      console.error('rec error', e);
      let errorMessage = 'Speech recognition error: ';
      
      switch(e.error) {
        case 'not-allowed':
          errorMessage += 'Microphone access denied. Please allow microphone access.';
          break;
        case 'no-speech':
          errorMessage += 'No speech detected. Please speak clearly.';
          break;
        case 'audio-capture':
          errorMessage += 'Audio capture failed. Check your microphone.';
          break;
        case 'network':
          errorMessage += 'Network error. Check your internet connection.';
          break;
        default:
          errorMessage += e.error;
      }
      
      alert(errorMessage);
      resetMicButton();
    };
    
    recognition.onend = () => {
      console.log('recognition ended');
      resetMicButton();
    };
    
    recognition.start();
    
  } catch (err) {
    console.error('Speech recognition setup failed:', err);
    alert('Speech recognition setup failed: ' + err.message);
  }
}

function resetMicButton() {
  const micBtn = document.getElementById('micBtn');
  if (micBtn) {
    micBtn.innerHTML = '🎙 Start Mic';
    micBtn.classList.remove('btn-primary');
    micBtn.classList.add('btn');
  }
}
function stopListening(){ if(recognition){ recognition.stop(); recognition=null; } }

let liveRec = null;
function startTranslateLive(){
  const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
  if(!SpeechRecognition){ alert('Speech Recognition not supported'); return; }
  if(liveRec){ liveRec.stop(); liveRec = null; }
  liveRec = new SpeechRecognition();
  liveRec.continuous = true;
  liveRec.interimResults = true;
  const from = $id('fromLang').value || 'en';
  liveRec.lang = langToLocale(from);

  liveRec.onresult = async (e) => {
    let finalTranscript = '';
    for(let i=0;i<e.results.length;i++){
      const res = e.results[i];
      if(res.isFinal){ finalTranscript += res[0].transcript + ' '; }
    }
    if(finalTranscript.trim()){
      $id('liveTranscript').innerText = finalTranscript;
      $id('inputText').value = finalTranscript;
      try{ await translateText(); } catch(ex){ console.error(ex); }
    }
  };
  liveRec.onerror = (ev)=> console.error('liveRec err', ev);
  liveRec.start();
}
function stopTranslateLive(){ if(liveRec){ liveRec.stop(); liveRec=null; } }

/* -------------------- Speak output -------------------- */
function speakText(){
  const text = $id('outputText').value;
  const to = $id('toLang').value || 'en';
  if(!text) return alert('Nothing to speak');
  const u = new SpeechSynthesisUtterance(text);
  u.lang = langToLocale(to);
  speechSynthesis.speak(u);
}

/* -------------------- Small utilities (copy/download) -------------------- */
function clearInput(){ $id('inputText').value=''; }
function copyOut(){ navigator.clipboard.writeText($id('outputText').value||''); }
function downloadTxt(name, text){
  const a = document.createElement('a');
  const blob = new Blob([text||''], {type:'text/plain'});
  a.href = URL.createObjectURL(blob);
  a.download = name;
  a.click();
  URL.revokeObjectURL(a.href);
}

// (optional) export some functions to window if your HTML uses inline onclick="..."
window.translateText = translateText;
window.grammarFix = grammarFix;
window.rewriteStyle = rewriteStyle;
window.startListening = startListening;
window.stopListening = stopListening;
window.startTranslateLive = startTranslateLive;
window.stopTranslateLive = stopTranslateLive;
window.speakText = speakText;
window.clearInput = clearInput;
window.copyOut = copyOut;
window.downloadTxt = downloadTxt;

// Add missing functions
function setTone(tone) {
  // This function can be expanded to apply tone-specific translations
  console.log('Tone set to:', tone);
  // For now, just log the tone selection
}

// Export all functions to window for inline onclick handlers
window.setTone = setTone;
window.handleDocUpload = handleDocUpload;
window.translateDocument = translateDocument;
window.downloadTranslatedPDF = downloadTranslatedPDF;
window.handleAudioUpload = handleAudioUpload;
window.transcribeAudio = transcribeAudio;
window.translateAudio = translateAudio;
window.handleVideoUpload = handleVideoUpload;
window.startVideoTranscription = startVideoTranscription;
window.stopVideoTranscription = stopVideoTranscription;
window.extractOCR = extractOCR;
window.renderSubtitleEditor = renderSubtitleEditor;
window.downloadSRT = downloadSRT;
window.downloadVTT = downloadVTT;
window.toSrtTime = toSrtTime;
window.toggleChat = toggleChat;
window.translateChat = translateChat;
window.clearChat = clearChat;
window.downloadChat = downloadChat;
window.exportChat = exportChat;

// Function to handle video links (YouTube/Vimeo)
function loadVideoFromLink() {
  const link = document.getElementById('videoLink').value.trim();
  if (!link) {
    alert('Please enter a video link');
    return;
  }
  
  // For now, show a message about link handling
  // In a production environment, you would need to implement proper video extraction
  const subtitleEditor = document.getElementById('subtitleEditor');
  subtitleEditor.innerHTML = '<div class="text-yellow-400 text-sm">⚠️ Video link processing requires server-side implementation. For now, please upload video files directly.</div>';
  
  // Clear the link input
  document.getElementById('videoLink').value = '';
}

window.loadVideoFromLink = loadVideoFromLink;

// Chat translator functionality
let chatMessages = [];

function toggleChat() {
  const chatInterface = document.getElementById('chatInterface');
  chatInterface.classList.toggle('active');
}

async function translateChat() {
  const input = document.getElementById('chatInput').value.trim();
  if (!input) {
    alert('Please enter a message to translate');
    return;
  }
  
  const fromLang = document.getElementById('chatFromLang').value || 'auto';
  const toLang = document.getElementById('chatToLang').value || 'en';
  
  try {
    // Translate the message
    const url = `https://translate.googleapis.com/translate_a/single?client=gtx&sl=${encodeURIComponent(fromLang)}&tl=${encodeURIComponent(toLang)}&dt=t&q=${encodeURIComponent(input)}`;
    const res = await fetch(url);
    if (!res.ok) throw new Error('HTTP ' + res.status);
    
    const data = await res.json();
    const translated = parseGoogleTranslate(data) || '';
    
    // Add message to chat history
    const message = {
      id: Date.now(),
      original: input,
      translated: translated,
      fromLang: fromLang,
      toLang: toLang,
      timestamp: new Date().toLocaleTimeString()
    };
    
    chatMessages.push(message);
    renderChatHistory();
    
    // Clear input
    document.getElementById('chatInput').value = '';
    
  } catch (err) {
    console.error('Chat translation failed:', err);
    alert('Translation failed: ' + err.message);
  }
}

function renderChatHistory() {
  const history = document.getElementById('chatHistory');
  if (chatMessages.length === 0) {
    history.innerHTML = '<div class="text-white/60 text-sm">Chat messages will appear here...</div>';
    return;
  }
  
  history.innerHTML = chatMessages.map(msg => `
    <div class="mb-3 p-2 bg-white/5 rounded">
      <div class="text-xs text-white/60 mb-1">${msg.timestamp} (${msg.fromLang} → ${msg.toLang})</div>
      <div class="text-white/80 mb-1"><strong>Original:</strong> ${msg.original}</div>
      <div class="text-white"><strong>Translated:</strong> ${msg.translated}</div>
    </div>
  `).join('');
  
  // Scroll to bottom
  history.scrollTop = history.scrollHeight;
}

function clearChat() {
  chatMessages = [];
  renderChatHistory();
}

function downloadChat() {
  if (chatMessages.length === 0) {
    alert('No chat messages to download');
    return;
  }
  
  const chatText = chatMessages.map(msg => 
    `[${msg.timestamp}] ${msg.fromLang} → ${msg.toLang}\nOriginal: ${msg.original}\nTranslated: ${msg.translated}\n`
  ).join('\n');
  
  downloadTxt('chat_translation.txt', chatText);
}

function exportChat() {
  if (chatMessages.length === 0) {
    alert('No chat messages to export');
    return;
  }
  
  const chatJson = JSON.stringify(chatMessages, null, 2);
  const blob = new Blob([chatJson], { type: 'application/json' });
  const url = URL.createObjectURL(blob);
  const a = document.createElement('a');
  a.href = url;
  a.download = 'chat_translation.json';
  a.click();
  URL.revokeObjectURL(url);
}

// Export chat functions to window
window.translateChat = translateChat;
window.clearChat = clearChat;
window.downloadChat = downloadChat;
window.exportChat = exportChat;

// Initialize the year in footer and add comprehensive error handling
document.addEventListener('DOMContentLoaded', function() {
  document.getElementById('y').textContent = new Date().getFullYear();
  
  // Check browser compatibility
  checkBrowserCompatibility();
  
  // Add user guidance
  addUserGuidance();
});

function checkBrowserCompatibility() {
  const issues = [];
  
  // Check Speech Recognition
  if (!window.SpeechRecognition && !window.webkitSpeechRecognition) {
    issues.push('Speech Recognition not supported - Voice features limited');
  }
  
  // Check File API
  if (!window.FileReader) {
    issues.push('File API not supported - Document upload limited');
  }
  
  // Check Web Audio API
  if (!window.AudioContext && !window.webkitAudioContext) {
    issues.push('Web Audio API not supported - Audio processing limited');
  }
  
  if (issues.length > 0) {
    console.warn('Browser compatibility issues:', issues);
    
    // Show user-friendly warning
    const warningDiv = document.createElement('div');
    warningDiv.className = 'message warning';
    warningDiv.innerHTML = `
      <div class="flex items-center space-x-2">
        <span>⚠️</span>
        <span><strong>Browser Compatibility Notice:</strong> Some features may be limited in your browser.</span>
      </div>
      <div class="text-xs mt-2">For best experience, use Chrome, Edge, or Firefox with latest updates.</div>
    `;
    
    // Insert after header
    const header = document.querySelector('header');
    if (header) {
      header.parentNode.insertBefore(warningDiv, header.nextSibling);
    }
  }
}

function addUserGuidance() {
  // Add helpful tooltips and guidance
  const tooltips = [
    { selector: '#fromLang', text: 'Select source language or use Auto Detect' },
    { selector: '#toLang', text: 'Choose target language for translation' },
    { selector: '#domain', text: 'Select context for better translation accuracy' },
    { selector: '#micBtn', text: 'Click to start voice input (requires microphone permission)' },
    { selector: '.chat-toggle', text: 'Access real-time chat translator' }
  ];
  
  tooltips.forEach(tooltip => {
    const element = document.querySelector(tooltip.selector);
    if (element) {
      element.title = tooltip.text;
    }
  });
}

  // --- Document parsing ---
  let lastDocText = '';
  async function handleDocUpload(e){
    const f = e.target.files[0]; if(!f) return;
    const orig = document.getElementById('docOriginal'); const translated = document.getElementById('docTranslated');
    orig.innerHTML = 'Loading...'; translated.innerHTML = '';
    const name = f.name.toLowerCase();
    
    try {
      if(name.endsWith('.docx')){
        const arrayBuffer = await f.arrayBuffer();
        const res = await mammoth.convertToHtml({arrayBuffer});
        orig.innerHTML = res.value;
        lastDocText = (res.value || '').replace(/<[^>]*>/g,' ');
      }else if(name.endsWith('.pdf')){
        const arrayBuffer = await f.arrayBuffer();
        const uint8 = new Uint8Array(arrayBuffer);
        const loadingTask = pdfjsLib.getDocument({data:uint8});
        const pdf = await loadingTask.promise;
        let full='';
        for(let i=1;i<=pdf.numPages;i++){ 
          const page = await pdf.getPage(i); 
          const content = await page.getTextContent(); 
          const strs = content.items.map(it=> it.str).join(' '); 
          full += ' ' + strs; 
        }
        orig.innerText = full.slice(0, 20000);
        lastDocText = full;
      }else if(name.endsWith('.pptx')){
        const arrayBuffer = await f.arrayBuffer();
        const zip = await JSZip.loadAsync(arrayBuffer);
        const slides = Object.keys(zip.files).filter(p=> p.startsWith('ppt/slides/slide'));
        let text='';
        for(const s of slides){ 
          const content = await zip.files[s].async('string');
          const t = (content.match(/<a:t>(.*?)<\/a:t>/g)||[]).map(x=> x.replace(/<.*?>/g,'')).join(' ');
          text += ' ' + t;
        }
        orig.innerText = text.slice(0,20000);
        lastDocText = text;
      }else{
        orig.innerText = 'Unsupported file format';
      }
    } catch(err) {
      orig.innerText = 'File parsing failed: ' + err.message;
      console.error('Document parsing error:', err);
    }
  }

  // --- Enhanced Document Translation with PDF Generation ---
  async function translateDocument(){
    if(!lastDocText){ alert('No document text loaded (upload a file first)'); return; }
    
    const translatedDiv = document.getElementById('docTranslated');
    translatedDiv.innerHTML = '<div class="text-yellow-400">🔄 Translating document... Please wait.</div>';
    
    const tgt = document.getElementById('toLang').value || 'en';
    const from = document.getElementById('fromLang').value || 'auto';
    const chunks = chunkString(lastDocText, 4000);
    let translated = '';
    
    try {
      for(let i = 0; i < chunks.length; i++){
        const c = chunks[i];
        const url = `https://translate.googleapis.com/translate_a/single?client=gtx&sl=${from}&tl=${tgt}&dt=t&q=${encodeURIComponent(c)}`;
        
        const r = await fetch(url); 
        const d = await r.json(); 
        
        if(Array.isArray(d) && d[0] && Array.isArray(d[0])){
          d[0].forEach(segment => {
            if(Array.isArray(segment) && segment[0]){
              translated += segment[0];
            }
          });
        }
        
        // Update progress
        const progress = Math.round(((i + 1) / chunks.length) * 100);
        translatedDiv.innerHTML = `<div class="text-blue-400">🔄 Translating... ${progress}% complete</div>`;
      }
      
      // Display translated text
      translatedDiv.innerHTML = `
        <div class="text-green-400 mb-2">✅ Translation complete!</div>
        <div class="text-white/80">${translated}</div>
      `;
      
      // Store translated text for PDF generation
      window.translatedDocumentText = translated;
      window.originalDocumentText = lastDocText;
      
    } catch(e){ 
      console.error('Document translation failed:', e); 
      translatedDiv.innerHTML = '<div class="text-red-400">❌ Translation failed: ' + e.message + '</div>';
    }
  }
  
  async function downloadTranslatedPDF() {
    if (!window.translatedDocumentText) {
      alert('Please translate a document first');
      return;
    }
    
    try {
      const { jsPDF } = window.jspdf;
      const doc = new jsPDF();
      
      // Set font for better language support
      doc.setFont('helvetica');
      doc.setFontSize(12);
      
      // Add title
      doc.setFontSize(16);
      doc.text('Translated Document', 20, 20);
      doc.setFontSize(12);
      
      // Add original and translated text
      const margin = 20;
      const lineHeight = 7;
      let y = 40;
      
      // Original text (first page)
      doc.setFontSize(14);
      doc.text('Original Text:', margin, y);
      y += lineHeight;
      doc.setFontSize(10);
      
      const originalLines = doc.splitTextToSize(window.originalDocumentText.substring(0, 1000), 170);
      doc.text(originalLines, margin, y);
      y += originalLines.length * lineHeight + 10;
      
      // Translated text (continue on same page if space, otherwise new page)
      if (y > 250) {
        doc.addPage();
        y = 20;
      }
      
      doc.setFontSize(14);
      doc.text('Translated Text:', margin, y);
      y += lineHeight;
      doc.setFontSize(10);
      
      const translatedLines = doc.splitTextToSize(window.translatedDocumentText, 170);
      doc.text(translatedLines, margin, y);
      
      // Save the PDF
      doc.save('translated_document.pdf');
      
    } catch (err) {
      console.error('PDF generation failed:', err);
      alert('PDF generation failed: ' + err.message);
    }
  }

  function chunkString(str, size){ const chunks=[]; for(let i=0;i<str.length;i+=size) chunks.push(str.slice(i,i+size)); return chunks; }

  let audioFile = null;
  let wavesurfer = null;
  
  function handleAudioUpload(e){ 
    const f = e.target.files[0]; 
    if(!f) return; 
    
    audioFile = f;
    
    // Initialize waveform visualization
    if (wavesurfer) {
      wavesurfer.destroy();
    }
    
    wavesurfer = WaveSurfer.create({
      container: '#audioVisualizer',
      waveColor: '#8b5cf6',
      progressColor: '#6ef3ff',
      cursorColor: '#ffffff',
      barWidth: 2,
      barRadius: 3,
      cursorWidth: 1,
      height: 80,
      barGap: 3
    });
    
    // Load audio file
    const url = URL.createObjectURL(f);
    wavesurfer.load(url);
    
    // Show success message
    document.getElementById('diarizeList').innerHTML = '<div class="text-green-400 text-sm">✅ Audio loaded successfully! Use "Transcribe Audio" to process.</div>';
  }
  
  async function transcribeAudio() {
    if (!audioFile) {
      alert('Please upload an audio file first');
      return;
    }
    
    try {
      // Create audio context for processing
      const audioContext = new (window.AudioContext || window.webkitAudioContext)();
      const arrayBuffer = await audioFile.arrayBuffer();
      const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
      
      // Extract audio data for analysis
      const channelData = audioBuffer.getChannelData(0);
      const sampleRate = audioBuffer.sampleRate;
      const duration = audioBuffer.duration;
      
      // Simple audio analysis (in a real implementation, you'd use more sophisticated algorithms)
      const segments = analyzeAudioSegments(channelData, sampleRate, duration);
      
      // Display results
      displayAudioAnalysis(segments);
      
      // Show transcription options
      document.getElementById('diarizeList').innerHTML = `
        <div class="text-green-400 text-sm mb-2">✅ Audio analysis complete!</div>
        <div class="text-white/80 text-sm">
          Duration: ${duration.toFixed(2)}s<br>
          Segments detected: ${segments.length}<br>
          <button class="btn text-xs mt-2" onclick="startAudioTranscription()">Start Live Transcription</button>
        </div>
      `;
      
    } catch (err) {
      console.error('Audio processing failed:', err);
      alert('Audio processing failed: ' + err.message);
    }
  }
  
  function analyzeAudioSegments(channelData, sampleRate, duration) {
    // Simple segment detection based on amplitude changes
    const segments = [];
    const segmentLength = 5; // 5 second segments
    const samplesPerSegment = segmentLength * sampleRate;
    
    for (let i = 0; i < channelData.length; i += samplesPerSegment) {
      const segmentData = channelData.slice(i, i + samplesPerSegment);
      const amplitude = Math.sqrt(segmentData.reduce((sum, sample) => sum + sample * sample, 0) / segmentData.length);
      
      if (amplitude > 0.01) { // Threshold for speech detection
        segments.push({
          start: i / sampleRate,
          end: Math.min((i + samplesPerSegment) / sampleRate, duration),
          amplitude: amplitude
        });
      }
    }
    
    return segments;
  }
  
  function displayAudioAnalysis(segments) {
    // This would display the audio analysis results
    console.log('Audio segments:', segments);
  }
  
  async function startAudioTranscription() {
    // Start live transcription using microphone
    startTranslateLive();
  }
  
  async function translateAudio() {
    if (!audioFile) {
      alert('Please upload an audio file first');
      return;
    }
    
    // For now, we'll use the live transcription approach
    // In a production environment, you'd implement server-side audio processing
    alert('Audio translation requires live transcription. Please use "Start Live Transcription" and play the audio file aloud near your microphone.');
  }

  // --- Video ---
  let subtitleSegments = [];
  
  function handleVideoUpload(e){ 
    const f = e.target.files[0]; 
    if(!f) return; 
    
    try {
      const url = URL.createObjectURL(f); 
      const v = document.getElementById('previewVideo'); 
      v.src = url; 
      v.load();
      
      // Clear previous subtitles
      subtitleSegments = [];
      renderSubtitleEditor();
      
      // Show success message
      const subtitleEditor = document.getElementById('subtitleEditor');
      subtitleEditor.innerHTML = '<div class="text-green-400 text-sm">Video loaded successfully! Use "Transcribe" to start capturing audio.</div>';
    } catch (err) {
      console.error('Video upload failed:', err);
      alert('Video upload failed: ' + err.message);
    }
  }

  let videoRec = null;
  function startVideoTranscription(){
    const v = document.getElementById('previewVideo'); 
    if(!v.src){ 
      alert('Load a video file or paste a link first'); 
      return; 
    }
    
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    if(!SpeechRecognition) return alert('SpeechRecognition not supported in this browser');
    
    // Clear previous subtitles
    subtitleSegments = [];
    
    const rec = new SpeechRecognition(); 
    rec.continuous = true; 
    rec.interimResults = false; 
    rec.lang = langToLocale(document.getElementById('fromLang').value || 'en');
    
    let seq = 0;
    rec.onresult = (e)=>{
      for(let i=0;i<e.results.length;i++){
        const r = e.results[i]; 
        if(r.isFinal){
          const text = r[0].transcript.trim(); 
          const seg = {
            id: ++seq, 
            startMS: Date.now(), 
            endMS: Date.now()+2000, 
            text
          }; 
          subtitleSegments.push(seg);
          renderSubtitleEditor();
        }
      }
    };
    
    rec.onerror = (ev)=> {
      console.error('video rec error',ev);
      alert('Speech recognition error: ' + ev.error);
    };
    
    rec.onend = () => {
      console.log('Video transcription ended');
      videoRec = null;
    };
    
    rec.start(); 
    videoRec = rec; 
    
    // Update UI to show transcription is active
    const subtitleEditor = document.getElementById('subtitleEditor');
    subtitleEditor.innerHTML = '<div class="text-yellow-400 text-sm">🎙️ Transcription active - play video loudly near microphone. Click "Stop" when done.</div>';
    
    alert('Recognition started — now play the video loudly so your microphone can capture it. Results are approximate.');
  }
  
  function stopVideoTranscription() {
    if (videoRec) {
      videoRec.stop();
      videoRec = null;
      const subtitleEditor = document.getElementById('subtitleEditor');
      if (subtitleSegments.length > 0) {
        subtitleEditor.innerHTML = '<div class="text-green-400 text-sm">Transcription stopped. You can now edit subtitles and download them.</div>';
      } else {
        subtitleEditor.innerHTML = '<div class="text-yellow-400 text-sm">No audio captured. Try playing the video louder or check microphone permissions.</div>';
      }
    }
  }

  function extractOCR(){
    const v = document.getElementById('previewVideo');
    if(!v || !v.src) return alert('Load video first');
    
    try {
      const canvas = document.createElement('canvas'); 
      canvas.width = v.videoWidth || 640; 
      canvas.height = v.videoHeight || 480;
      const ctx = canvas.getContext('2d'); 
      ctx.drawImage(v, 0, 0, canvas.width, canvas.height); 
      
      // Show canvas for user to see what's being processed
      canvas.style.maxWidth = '100%';
      canvas.style.border = '2px solid #8b5cf6';
      canvas.style.borderRadius = '0.5rem';
      canvas.style.margin = '1rem 0';
      
      // Remove any existing canvas
      const existingCanvas = document.querySelector('#ocrCanvas');
      if (existingCanvas) existingCanvas.remove();
      
      canvas.id = 'ocrCanvas';
      document.getElementById('subtitleEditor').appendChild(canvas);
      
      // Process OCR
      Tesseract.recognize(canvas, 'eng').then(({data})=>{
        const ocrText = data.text.trim();
        if (ocrText) {
          // Add OCR text to subtitle segments
          const seg = {
            id: subtitleSegments.length + 1,
            startMS: Date.now(),
            endMS: Date.now() + 3000,
            text: ocrText
          };
          subtitleSegments.push(seg);
          renderSubtitleEditor();
          alert('OCR completed! Text added to subtitles: ' + ocrText.slice(0, 100));
        } else {
          alert('No text detected in the frame');
        }
      }).catch(e=> {
        console.error('OCR failed:', e);
        alert('OCR failed: ' + e.message);
      });
    } catch (err) {
      console.error('OCR setup failed:', err);
      alert('OCR setup failed: ' + err.message);
    }
  }

  function renderSubtitleEditor(){
    const el = document.getElementById('subtitleEditor');
    if(!subtitleSegments.length){ el.innerText = 'No subtitles yet.'; return; }
    el.innerHTML = '';
    subtitleSegments.forEach((s,i)=>{
      const div = document.createElement('div'); div.className='subtitle-segment';
      div.innerHTML = `<div class='text-xs text-white/60'>Segment ${i+1} — approx ${new Date(s.startMS).toLocaleTimeString()}</div><div contenteditable='true' class='mt-1 text-white'>${s.text}</div>`;
      el.appendChild(div);
    });
  }

  async function downloadSRT(){
    if(!subtitleSegments.length) return alert('No subtitles to download');
    
    const targetLang = document.getElementById('subtitleLang').value || 'en';
    let srtContent = '';
    
    if (targetLang === 'en') {
      // Use original text
      srtContent = subtitleSegments.map((s,i)=>`${i+1}
${toSrtTime(s.startMS)} --> ${toSrtTime(s.startMS + 3000)}
${s.text}`).join('\n\n');
    } else {
      // Translate subtitles to target language
      srtContent = await generateTranslatedSubtitles(targetLang, 'srt');
    }
    
    downloadTxt('subtitles.srt', srtContent);
  }

  async function downloadVTT(){
    if(!subtitleSegments.length) return alert('No subtitles to download');
    
    const targetLang = document.getElementById('subtitleLang').value || 'en';
    let vttContent = '';
    
    if (targetLang === 'en') {
      // Use original text
      vttContent = 'WEBVTT\n\n' + subtitleSegments.map(s=> `${toSrtTime(s.startMS)} --> ${toSrtTime(s.startMS + 3000)}\n${s.text}`).join('\n\n');
    } else {
      // Translate subtitles to target language
      vttContent = await generateTranslatedSubtitles(targetLang, 'vtt');
    }
    
    downloadTxt('subtitles.vtt', vttContent);
  }
  
  async function generateTranslatedSubtitles(targetLang, format) {
    try {
      let translatedContent = '';
      
      if (format === 'srt') {
        for (let i = 0; i < subtitleSegments.length; i++) {
          const s = subtitleSegments[i];
          const translatedText = await translateSubtitleText(s.text, targetLang);
          
          translatedContent += `${i+1}
${toSrtTime(s.startMS)} --> ${toSrtTime(s.startMS + 3000)}
${translatedText}\n\n`;
        }
      } else if (format === 'vtt') {
        translatedContent = 'WEBVTT\n\n';
        for (let s of subtitleSegments) {
          const translatedText = await translateSubtitleText(s.text, targetLang);
          translatedContent += `${toSrtTime(s.startMS)} --> ${toSrtTime(s.startMS + 3000)}\n${translatedText}\n\n`;
        }
      }
      
      return translatedContent;
    } catch (err) {
      console.error('Subtitle translation failed:', err);
      alert('Subtitle translation failed: ' + err.message);
      return '';
    }
  }
  
  async function translateSubtitleText(text, targetLang) {
    try {
      const url = `https://translate.googleapis.com/translate_a/single?client=gtx&sl=auto&tl=${encodeURIComponent(targetLang)}&dt=t&q=${encodeURIComponent(text)}`;
      const res = await fetch(url);
      if (!res.ok) throw new Error('HTTP ' + res.status);
      
      const data = await res.json();
      return parseGoogleTranslate(data) || text;
    } catch (err) {
      console.error('Text translation failed:', err);
      return text; // Return original text if translation fails
    }
  }

  function toSrtTime(ms){
    const d = new Date(ms);
    const h = String(d.getUTCHours()).padStart(2,'0');
    const m = String(d.getUTCMinutes()).padStart(2,'0');
    const s = String(d.getUTCSeconds()).padStart(2,'0');
    const msPart = String(ms%1000).padStart(3,'0');
    return `${h}:${m}:${s},${msPart}`;
  }
</script>
</body>
</html>
